{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu configuration\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input,Lambda,Dense,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18632\n"
     ]
    }
   ],
   "source": [
    "#Training images and csv\n",
    "train_images=glob('../input/plant-pathology-2021-fgvc8/train_images/*')\n",
    "train_csv=pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\n",
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv=pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\n",
    "print(submission_csv.head(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[:10])\n",
    "print(train_csv.head(n=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert target to numeric data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe=OrdinalEncoder(dtype=int)\n",
    "train_csv['labels']=oe.fit_transform(train_csv[['labels']])\n",
    "\n",
    "print(type(train_csv))\n",
    "print(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the label column\n",
    "train_labels=train_csv.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load half of thr training dataset due to memory issues\n",
    "train_copy=train_images[:500]\n",
    "print(len(train_copy))\n",
    "labels_copy=train_labels[:500]\n",
    "print(len(labels_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for imbalancednes among the training labels\n",
    "from collections import Counter\n",
    "print(Counter(labels_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique diseases\n",
    "out_shape=labels_copy.nunique()\n",
    "print(out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very imblanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(train_labels)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test images loading\n",
    "test_images=glob('../input/plant-pathology-2021-fgvc8/test_images/*')\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the images at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io \n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_files=train_csv['image']\n",
    "\n",
    "#Visualize the images randomly from the dataset\n",
    "n=np.random.randint(0,18692,1)[0]\n",
    "img=io.imread('../input/plant-pathology-2021-fgvc8/train_images/'+flower_files[n])\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(rgb_img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Images to array\n",
    "train = []\n",
    "test=[]\n",
    "\n",
    "for myFile in train_images:\n",
    "    im=cv2.imread(myFile, cv2.COLOR_BGR2RGB)\n",
    "    img=cv2.resize(im,(224,224))\n",
    "    image=np.asarray(img,dtype=np.float32)\n",
    "    train.append(image)\n",
    "\n",
    "for myFile in test_images:\n",
    "    im=cv2.imread(myFile,cv2.COLOR_BGR2RGB)\n",
    "    img=cv2.resize(im,(224,224))\n",
    "    image=np.asarray(img,dtype=np.float32)\n",
    "    test.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as  h5py file\n",
    "import h5py\n",
    "with h5py.File('train.h5','w') as h5f:\n",
    "    h5f.create_dataset('arrays',data=np.asarray(train))\n",
    "\n",
    "with h5py.File('test.h5','w') as h5f:\n",
    "    h5f.create_dataset('arrays',data=np.asarray(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X_train,y_train and test\n",
    "X_train=np.asarray(train,dtype=np.float32)\n",
    "X= X_train.reshape(-1,224,224,3)/255\n",
    "print(X_train.shape,\",\",X_train.dtype)\n",
    "y= np.array(labels_copy)\n",
    "print(y_train.dtype,\":\",y_train.shape)\n",
    "test=np.asarray(test,dtype=np.float32).reshape(-1,224,224,3)/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data using ImagedataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will add .png to every observation in the id column.Useful when not present.\n",
    "def append_ext(fn):\n",
    "    return fn+\".png\"def append_ext(fn):\n",
    "    return fn+\".png\"\n",
    "\n",
    "traindf=pd.read_csv(“./trainLabels.csv”,dtype=str)\n",
    "\n",
    "testdf=pd.read_csv(\"./sampleSubmission.csv\",dtype=str)traindf[\"id\"]=traindf[\"id\"].apply(append_ext)\n",
    "\n",
    "testdf[\"id\"]=testdf[\"id\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would have noticed, I appended “.png” to all the filenames in the “id” column of the dataframe to convert the file ids to actual filenames(depending upon the dataset you might want to handle this accordingly), previously that was handled automatically by “has_ext” attribute which is now deprecated for various reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "train_datagen=ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,\n",
    "                                 horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generate training data\n",
    "train_generator=train_datagen.flow_from_dataframe(dataframe=train_csv[:5000],directory='../input/plant-pathology-2021-fgvc8/train_images',\n",
    "                                            x_col='image',y_col='labels',subset='training',\n",
    "                                            batch_size=32,seed=42,shuffle=False,\n",
    "                                            class_mode='categorical',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate validation data\n",
    "valid_generator=train_datagen.flow_from_dataframe(dataframe=train_csv[5000:6500],directory='../input/plant-pathology-2021-fgvc8/train_images',\n",
    "                                            x_col='image',y_col='labels',subset='training',\n",
    "                                            batch_size=32,seed=42,shuffle=False,\n",
    "                                            class_mode='categorical',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate test data\n",
    "test_generator=test_datagen.flow_from_dataframe(dataframe=submission_csv,directory='../input/plant-pathology-2021-fgvc8/test_images',\n",
    "                                          target_size=(224, 224),batch_size=32,x_col='image',\n",
    "                                          class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-size all the images to this\n",
    "IMAGE_SIZE=[224, 224]\n",
    "\n",
    "#ResNet50\n",
    "resnet=ResNet50(input_shape=IMAGE_SIZE + [3],weights='imagenet',include_top=False)\n",
    "\n",
    "#don't train existing weights\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "#Faltten the layers\n",
    "x=Flatten()(resnet.output)\n",
    "\n",
    "#Final dense output layer\n",
    "prediction=Dense(12,activation='softmax')(x)\n",
    "\n",
    "#create a model object\n",
    "model=Model(inputs=resnet.input,outputs=prediction)\n",
    "\n",
    "#view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "from keras.optimizers import Adam\n",
    "adam=Adam(learning_rate=3e-4)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "callback_list=[EarlyStopping(monitor='accuracy',patience=5)]\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callback_list,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('resnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#re-size all the images to this\n",
    "IMAGE_SIZE=[224, 224]\n",
    "\n",
    "#InceptionV3\n",
    "inc_v3=InceptionV3(input_shape=IMAGE_SIZE + [3],pooling='avg',weights='imagenet',\n",
    "                   include_top=False)\n",
    "\n",
    "#don't train existing weights\n",
    "for layer in inc_v3.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "#Faltten the layers\n",
    "x=Flatten()(inc_v3.output)\n",
    "\n",
    "#Final dense output layer\n",
    "prediction=Dense(12,activation='softmax')(x)\n",
    "\n",
    "#create a model object\n",
    "model=Model(inputs=inc_v3.input,outputs=prediction)\n",
    "\n",
    "#view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "from keras.optimizers import Adam\n",
    "adam=Adam(learning_rate=3e-4)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "callback_list=[EarlyStopping(monitor='accuracy',patience=5)]\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callback_list,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the accuracy\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('inception_v31 .h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "model=load_model('../input/inceptionv3/inception_v31 .h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 772ms/step\n",
      "<bound method NDFrame.head of                   image              labels\n",
      "0  85f8cb619c66b863.jpg  frog_eye_leaf_spot\n",
      "1  ad8770db05586b59.jpg             complex\n",
      "2  c7b03e718489f3ca.jpg  frog_eye_leaf_spot>\n"
     ]
    }
   ],
   "source": [
    "#Predict using predict_generator\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels=(train_generator.class_indices)\n",
    "labels=dict((v,k) for k,v in labels.items())\n",
    "predictions=[labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({'image':filenames,\n",
    "                      'labels':predictions})\n",
    "print(results.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the file\n",
    "import os\n",
    "os.remove('./sample_submission.csv')\n",
    "os.remove('./results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
